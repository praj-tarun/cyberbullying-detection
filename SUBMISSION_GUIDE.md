# Submission Guide - Identifying Cyberbullying in Social Media Posts

## Project Structure

```
DL/
├── src/                        # Source code
│   ├── models.py              # LSTM, CNN, BERT architectures
│   ├── train.py               # Training utilities
│   ├── utils.py               # Evaluation functions
│   └── inference.py           # Inference script
├── notebooks/                  # Jupyter notebooks
│   ├── Preprocessing.ipynb    # Data exploration
│   ├── lstm_model.ipynb       # LSTM (Member 1)
│   ├── cnn_model.ipynb        # CNN (Member 2)
│   ├── ensemble_model.ipynb   # Ensemble (Member 3)
│   └── bert_model.ipynb       # BERT (Member 4)
├── outputs/                    # Saved models and plots
├── data/raw/                   # Dataset (not included in submission)
├── README.md                   # Main documentation
├── PROJECT_REPORT.md           # 4-page report
├── TEAM_ASSIGNMENTS.md         # Team responsibilities
└── requirements.txt            # Dependencies

```

## Before Submission

### 1. Complete All Notebooks
- [ ] lstm_model.ipynb executed
- [ ] cnn_model.ipynb executed
- [ ] ensemble_model.ipynb executed
- [ ] bert_model.ipynb executed

### 2. Fill Report
- [ ] Section 6.1: Overall performance metrics
- [ ] Section 6.2: Per-label F1 scores
- [ ] Section 6.3: Training times

### 3. Verify Files
- [ ] All notebooks have outputs visible
- [ ] Models saved in outputs/
- [ ] Plots generated in outputs/
- [ ] README.md is complete
- [ ] PROJECT_REPORT.md is complete

### 4. Test Code
```bash
# Test inference
python -m src.inference

# Verify imports work
python -c "from src.models import LSTMClassifier, SimpleCNN, BERTClassifier"
```

## Creating Submission

### 1. Clean Up (Optional)
Remove large model files if needed:
```bash
# Keep only essential files
# Models can be regenerated by running notebooks
```

### 2. Create Zip
```bash
# Windows
Compress-Archive -Path DL -DestinationPath group_05.zip

# Or use File Explorer: Right-click folder → Send to → Compressed folder
```

### 3. Rename
Rename to your actual group number (e.g., `group_05.zip`)

## What to Include

**Must Include**:
- All source code (src/)
- All notebooks with outputs
- README.md
- PROJECT_REPORT.md
- requirements.txt
- TEAM_ASSIGNMENTS.md

**Optional** (if size permits):
- Saved models (outputs/*.pt)
- Generated plots (outputs/*.png)
- Vocabulary files (outputs/*.pkl)

**Do Not Include**:
- Dataset files (data/raw/*.csv) - too large
- Python cache (__pycache__/)
- Jupyter checkpoints (.ipynb_checkpoints/)

## Dataset Instructions

Since dataset is not included, README.md provides:
1. Download link (Kaggle)
2. Installation command (kaggle CLI)
3. Extraction instructions

Reviewers can download dataset using provided instructions.

## Running Submitted Code

Reviewers will:
1. Extract zip file
2. Install dependencies: `pip install -r requirements.txt`
3. Download dataset following README.md
4. Run notebooks or training script
5. Verify results match report

## Checklist

- [ ] All code runs without errors
- [ ] README.md has clear instructions
- [ ] PROJECT_REPORT.md is under 4 pages
- [ ] Notebooks have visible outputs
- [ ] requirements.txt is complete
- [ ] Zip file named correctly (group_05.zip or your group number)
- [ ] Dataset download instructions provided

## File Sizes

Approximate sizes:
- Source code: <100 KB
- Notebooks: ~1-5 MB (with outputs)
- Models: ~450 MB (LSTM + CNN + BERT)
- Total without models: ~10 MB
- Total with models: ~460 MB

If submission size limit is exceeded, exclude model files and note in README that they can be regenerated.

## Contact

If reviewers have issues running code:
- Check README.md for setup instructions
- Verify all dependencies installed
- Ensure dataset downloaded correctly
- Check Python version (3.8+)
